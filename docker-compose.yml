version: '3.8'

services:
  # Ollama service for AI OCR (optional, improves accuracy)
  ollama:
    image: ollama/ollama:latest
    container_name: ttb-ollama
    ports:
      - "11435:11434"
    volumes:
      - ollama_models:/root/.ollama
    # Note: GPU support disabled for compatibility
    # To enable GPU, uncomment the deploy section below
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    networks:
      - ttb-network

  # Main TTB Label Verifier API
  verifier:
    build:
      context: .
      target: production
    container_name: ttb-verifier
    ports:
      - "8000:8000"
    environment:
      # Ollama configuration
      - OLLAMA_HOST=${OLLAMA_HOST:-http://ollama:11434}
      # Model name - change to use custom models from S3 or Ollama registry
      # Custom models should be uploaded to s3://{bucket}/models/{MODEL_NAME}.tar.gz
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2-vision}
      
      # App configuration
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - MAX_FILE_SIZE_MB=${MAX_FILE_SIZE_MB:-10}
      - MAX_BATCH_SIZE=${MAX_BATCH_SIZE:-50}
      - DEFAULT_OCR_BACKEND=${DEFAULT_OCR_BACKEND:-tesseract}
      
      # UI configuration - set your domain for host checking
      # For local development, set to localhost or use .env file
      - DOMAIN_NAME=${DOMAIN_NAME:-localhost}
      # Alternatively, set allowed hosts directly:
      # - ALLOWED_HOSTS=${ALLOWED_HOSTS:-["localhost", "127.0.0.1"]}
      
      # Temp directory for file uploads (avoid tmpfs space issues)
      - TMPDIR=/app/tmp
      
      # CORS (allow all for prototype)
      - CORS_ORIGINS=${CORS_ORIGINS:-["*"]}
    volumes:
      # Mount host directory for temp file storage during uploads
      - ./tmp:/app/tmp
    depends_on:
      - ollama
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - ttb-network

volumes:
  ollama_models:
    driver: local

networks:
  ttb-network:
    driver: bridge
